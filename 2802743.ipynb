{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 0.简介\n",
    "\n",
    "**一枚热爱技术的菜鸡，今天想做一个目标检测和嵌入式的结合体，做一个jetson nano乐器**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a85fbc34eda64015a2bada1221cc9a1be300784ca9204613b3e9b94511f5b0a4)\n",
    "\n",
    "**方案：**\n",
    "\n",
    "**使用paddledetection训练模型并使用paddleInference在jetson nano上部署目标检测网络，**\n",
    "\n",
    "**使用Tensorrt进行Jetsonnano的加速，**\n",
    "\n",
    "**来挽救我的2GB版本的nano的性能拉跨，**\n",
    "\n",
    "**达到一个令人满意的FPS，检测简单手势，**\n",
    "\n",
    "**然后再通过nano控制beep等外设，来达到beep的变频输出**\n",
    "\n",
    "**使用7种手势代表7种音阶**\n",
    "\n",
    "**do、re、mi、fa、sol、la、si**\n",
    "\n",
    "**且为了使得音调更加丰富，我使用了第八种手势，当第八种手势出现在画面中的时候，音阶就会上抬一个八度,于是我们获得了十四个音阶**\n",
    "\n",
    "**do、re、mi、fa、sol、la、si、ddo、dre、dmi、dfa、dsol、dla、dsi**\n",
    "\n",
    "**从左向右从上往下依次是12 .....最后一个是音阶抬高记号**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d50c1e8b7da04d5093b6ba37786e4fd83bf4d9cd2a7b4f348460b3188d34e15a)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1.数据集制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#在本地上执行\r\n",
    "pip install labelimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "安装labelimg\n",
    "\n",
    "打开labelimg界面如下\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/41858aa1fccf42fb86c5e97c201724621ffe28f8c8bb45aeaf28787b78f29f93)\n",
    "\n",
    "标注完成后voc数据集结构如下\n",
    "\n",
    "  │├── Annotations**\n",
    "  \n",
    "  │├── one0.xml\n",
    "  \n",
    "  │├── one1.xml\n",
    "  \n",
    "  │├   ...\n",
    "  \n",
    "  │├── JPEGImages\n",
    "  \n",
    "  │├── one0.jpg\n",
    "  \n",
    "  │├── one1.jpg\n",
    "  \n",
    "  │├   ...\n",
    "  \n",
    "  │├── ImageSets\t\n",
    "  \n",
    "  │├──create_txt.py**\n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2.paddledet环境的aistudio部署\n",
    "\n",
    "打开aistudio\n",
    "\n",
    "`pip list`\n",
    "\n",
    "我们的aistudio环境已经配置好了paddle环境，所以不需要我们自己去设置\n",
    "\n",
    "通过pip list\n",
    "\n",
    "我们可以看到环境为paddle2.2.0gpu版本\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c2018c1afc0e42fe82c9b2c6a130ad735628c9303a3a460896080214fc7db4b8)\n",
    "\n",
    "\n",
    "话不多说,首先在终端执行 \n",
    "\n",
    "`!git clone https://gitee.com/paddlepaddle/PaddleDetection.git`\n",
    "\n",
    "将paddledetection在gitee的代码拷贝下来\n",
    "\n",
    "当看见命令行出现下面这串代码时，即表示我们已经完成了代码的拷贝\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/9f8d2cc749474d1aa62c3103bdbc70dd977616000e814b7996f554706c62add4)\n",
    "\n",
    "命令行输入ls进入文件夹\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/49cef3e13f654643ae8d8f45e87bfd35eb66b866fc364f1ca304a9cfc7c52b2f)\n",
    "\n",
    "\n",
    "我们就可以看得到paddledetection的文件夹\n",
    "\n",
    "`#进入文件夹`\n",
    "\n",
    "`%cd PaddleDetection/`\n",
    "\n",
    "`#安装其他依赖`\n",
    "\n",
    "`!pip install -r requirements.txt`\n",
    "\n",
    "`#编译安装paddledet`\n",
    "\n",
    "`%cd PaddleDetection`\n",
    "\n",
    "`!python setup.py install`\n",
    "\n",
    "当命令行最后一行执行出现\n",
    "\n",
    "`Finished processing dependencies for paddledet==2.3.0` 时\n",
    "\n",
    "至此,环境部署完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3.VOC数据集的上传与训练configs的修改\n",
    "\n",
    "点击jupyter notebook左上方的\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/57782f08dc76488e8ea4ec6ee318315dd87a3b0cc6a642ef902b3aa2be5a3e1e)\n",
    "\n",
    "\n",
    "此时，数据集已经上载，但若要使用需要将数据集放到PaddleDetection中dataset文件夹下一级的voc文件夹中\n",
    "\n",
    "退回到home\n",
    "\n",
    "然后我们在命令行输入\n",
    "\n",
    "`cp Music.zip /PaddleDetection/dataset/voc`\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/115871912dcd4f79815f3b2d8a1358912388b20516f3456096aac49008677f50)\n",
    "\n",
    "成功地将压缩文件粘贴至目标文件夹下\n",
    "\n",
    "下面解压\n",
    "\n",
    "**建议压缩数据集时候压缩成zip格式，然后上传zip，aistudio中不自带unrar命令**\n",
    "\n",
    "这里不在赘述\n",
    "\n",
    "使用unzip解压Music.zip\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5ea68787e59d4a7d934b1ca19278804325442a3cb34a4a6eab114c268b8994e6)\n",
    "\n",
    "完成解压\n",
    "\n",
    "下面我们使用paddledetection对ppyolo进行训练\n",
    "\n",
    "进入PaddleDetection文件夹下的config/ppyolo文件夹,选择我们想要的模型\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/32db15a05e9c434d83a68a84cab8eaee3cf2b2317e25477f8a87a59ad7a141b5)\n",
    "\n",
    "这里我选择ppyolo_r50vd_dcn，使用vim打开对应的yml文件\n",
    "\n",
    "输入命令\n",
    "\n",
    "`vim ppyolo_r50vd_dcn_voc.yml`\n",
    "\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/2e5ba1fb84554d6286b6649f92b7f6242aa9eea76aa34679bc4f13f4ae850229)\n",
    "\n",
    "可以看到__BASE__下的是该模型所对应的configs\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/21c61b312aab42fc9fde3c6c77294dbac8bf5bf69c794c41a5ce5aa759864ba9)\n",
    "\n",
    "这些config对应的是训练时的各种设置，至于具体内容对应什么，可以翻阅paddle的[官方文档](https://gitee.com/paddlepaddle/PaddleDetection/blob/release/2.3/docs/tutorials/GETTING_STARTED_cn.md)\n",
    "\n",
    "我们需要对voc.yml的文件内容做一点更改\n",
    "\n",
    "进入对应的文件目录，使用vim打开voc.yml\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/842e080988d441ba9b6f44a2f93dd63b6c73a17e11be4e5084be0791e25a8d59)\n",
    "\n",
    "更改为如下代码\n",
    "\n",
    "```\n",
    "metric: VOC\n",
    "map_type: 11point\n",
    "num_classes: 8\n",
    "\n",
    "TrainDataset:\n",
    "  !VOCDataSet\n",
    "    dataset_dir: ../dataset/voc/Music\n",
    "    anno_path: ImageSets/train.txt\n",
    "    label_list: ImageSets/label_list.txt\n",
    "    data_fields: ['image', 'gt_bbox', 'gt_class', 'difficult']\n",
    "\n",
    "EvalDataset:\n",
    "  !VOCDataSet\n",
    "    dataset_dir: ../dataset/voc/Music\n",
    "    anno_path: ImageSets/val.txt\n",
    "    label_list: ImageSets/label_list.txt\n",
    "    data_fields: ['image', 'gt_bbox', 'gt_class', 'difficult']\n",
    "\n",
    "TestDataset:\n",
    "  !ImageFolder\n",
    "    anno_path: ../dataset/voc/Music/ImageSets/label_list.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "因为我制作的数据集地址是在原定基础上多出了一个Music文件夹，然后num_classes需要更改为8个，因为八种手势对应着8种音符\n",
    "\n",
    "然后我们还需要执行以下Music文件夹下的create_txt.py文件，因为数据集是从我电脑上移植过来的，所以annotation中所对应的图片地址都是我的电脑上的，所以如果需要正确训练，需要将地址更改为aistudio上的对应地址\n",
    "\n",
    "\n",
    "* create_txt.py长这样\n",
    "\n",
    "```\n",
    "import random\n",
    "import os\n",
    "#生成train.txt和val.txt\n",
    "random.seed(2021)\n",
    "xml_dir  = r'./Annotations'#标签文件地址\n",
    "img_dir = r'./JPEGImages'#图像文件地址\n",
    "path_list = list()\n",
    "for img in os.listdir(img_dir):\n",
    "    img_path = os.path.join(img_dir,img)\n",
    "    xml_path = os.path.join(xml_dir,img.replace('jpg', 'xml'))\n",
    "    path_list.append((img_path, xml_path))\n",
    "random.shuffle(path_list)\n",
    "ratio = 0.9\n",
    "train_f = open(r'./ImageSets/train.txt','w') #生成训练文件\n",
    "val_f = open(r'./ImageSets/val.txt' ,'w')#生成验证文件\n",
    "\n",
    "for i ,content in enumerate(path_list):\n",
    "    img, xml = content\n",
    "    text = img + ' ' + xml + '\\n'\n",
    "    if i < len(path_list) * ratio:\n",
    "        train_f.write(text)\n",
    "    else:\n",
    "        val_f.write(text)\n",
    "train_f.close()\n",
    "val_f.close()\n",
    "\n",
    "#生成标签文档\n",
    "label = ['one','two','three','four','five','six','seven','eight']#设置你想检测的类别\n",
    "with open(r'./ImageSets/label_list.txt', 'w') as f:\n",
    "    for text in label:\n",
    "        f.write(text+'\\n')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 4.开始训练！\n",
    "进入tools文件夹输入命令\n",
    "\n",
    "`python train -c ../configs/ppyolo/ppyolo_r50vd_dcn_voc.yml`\n",
    "\n",
    "\n",
    "开始激动人心的训练！\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ffdb78358e3c4bda8b7ecc110772084425589d75fcf04df4824cb47c02341acb)\n",
    "\n",
    "训练完成，使用infer.py进行预测\n",
    "\n",
    "在tool文件夹下输入命令\n",
    "\n",
    "`python infer.py -c ../configs/ppyolo/ppyolo_r50vd_dcn_voc.yml --infer_img=one.jpg`\n",
    "\n",
    "* 这里我把测试图片放在了tool文件夹下面了\n",
    "\n",
    "出现以下内容\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/b0a30e97016a4cfa8bf0334c81e9dee1359e68836b754374abcf7a536bb693f6)\n",
    "\n",
    "完成预测\n",
    "\n",
    "预测结果如下：（注：后面更换了数据集，所以跟一开始这张图片不一样）\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c62b3c1de0154ab2ba1c8915f30dc54c31ff7a299a4b4222afc352479186ef23)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 5.进行模型评估\n",
    "\n",
    "在tools文件夹下，使用命令\n",
    "\n",
    "`python eval.py -c ../configs/ppyolo/ppyolo_r50vd_dcn_voc.yml`\n",
    "\n",
    "我们可以看见eval的结果，mAP达到了%94.82\n",
    "\n",
    "目前采样了24张图像，预计视频检测帧能达到25FPS(aistudio上)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/63d2e0cbeec04cfabecc29678a9b9185d379858c1fd746908a825b22fd7091af)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 6.JetsonNano的部署\n",
    "\n",
    "我这里有一块上好的JetsonNano 2GB版，在同一局域网下使用ssh连接\n",
    "\n",
    "使用\n",
    "\n",
    "`nvcc -V`\n",
    "\n",
    "来查看cuda版本\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/3719362c465246a2aeb5c55ccef2aa9ec2416d7a555548c2a5269ed7d12522eb)\n",
    "\n",
    "这里可以看到我的cuda是10.2的\n",
    "\n",
    "* 首先我们来部署paddledet\n",
    "\n",
    "如同aistudio上部署一样，我们依然需要先git clone以下paddledetection的库这里不再赘述\n",
    "\n",
    "`git clone https://gitee.com/paddlepaddle/PaddleDetection.git`\n",
    "\n",
    "依然是\n",
    "\n",
    "`#进入文件夹`\n",
    "\n",
    "`cd PaddleDetection/`\n",
    "\n",
    "`#安装其他依赖`\n",
    "\n",
    "`pip3 install -r requirements.txt`\n",
    "\n",
    "`#编译安装paddledet`\n",
    "\n",
    "`cd PaddleDetection`\n",
    "\n",
    "`python3 setup.py install`\n",
    "\n",
    "当命令行最后一行执行出现\n",
    "\n",
    "`Finished processing dependencies for paddledet==2.3.0` \n",
    "\n",
    "完成安装\n",
    "\n",
    "通过后可以通过\n",
    "\n",
    "`python ppdet/modeling/tests/test_architectures.py`\n",
    "\n",
    "检测一下是否成功\n",
    "\n",
    "出现下图时即可判定成功\n",
    "\n",
    "按照官方给的[教程](https://gitee.com/paddlepaddle/PaddleDetection/blob/release/2.3/docs/tutorials/INSTALL_cn.md)来即可，或者好像可以直接pip安装包，连编译都不要\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e57463f46ea54a399599c6d0f48fa0c9d3c0d8ae6da7457a992e67c63482416c)\n",
    "\n",
    "* 2G没使用Tensorrt的算力就是弱，跑了我46秒多\n",
    "\n",
    "这里可以看见报了个Warning，不过不用担心，只要不是Error就可以当作看不见🤭\n",
    "\n",
    "现在可以把我们训练好的模型放入进行预测，不过得先更改一下configs配置的相关内容\n",
    "\n",
    "找到configs下datasets中的voc.yml\n",
    "\n",
    "`vim voc.yml`\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ffd28d2043b7415ba6cb6e795089c6ff85020c5c76d44b51897b95e78e4c18bd)\n",
    "\n",
    "更改为\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c04a9e2469d843ddb472a4dd7c89328fdb47d1951514465492f452a8e5488b64)\n",
    "\n",
    "就是地址改一改，classnum改一改\n",
    "\n",
    "别忘记把labellist放上去，这个时候不用放数据集了\n",
    "\n",
    "训练好的权重放在一个自己喜欢的地方即可，等会命令行调用的时候改一下地址即可\n",
    "\n",
    "在tool文件夹下执行\n",
    "\n",
    "`python3 infer.py -c ../configs/ppyolo/ppyolo_r50vd_dcn_voc.yml --infer_img=one1.jpg -o weights=model_final.pdparams`\n",
    "\n",
    "注意，jetsonnano中直接使用python是调用python2，而使用python3的时候才是调用python3的\n",
    "\n",
    "* 不过，性能实在太差，运行了6分种左右被系统Killed了\n",
    "\n",
    "部署还是没有问题的，这也就凸显出tensorrt的必要了\n",
    "\n",
    "* 下面进行paddleinference的部署（可以调用tensorrt进行加速）\n",
    "\n",
    "\n",
    "在aistudio中进行模型的导出\n",
    "\n",
    "\n",
    "`python export_model.py -c ../configs/yolov3/yolov3_darknet53_270e_voc.yml  -o weights=model_final.pdparams`\n",
    "\n",
    "将模型导出到\n",
    "\n",
    "inference_model/yolov3_darknet53_270e_voc文件夹下\n",
    "\n",
    "分别为\n",
    "infer_cfg.yml, model.pdiparams, model.pdiparams.info, model.pdmodel\n",
    "\n",
    "通过使用这些导出的模型文件可以使用Jetson nano带的Tensorrt加速\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "下面进行paddle_inference的部署\n",
    "\n",
    "使用 `git clone https://gitee.com/myxxr/paddle-inference.git`\n",
    "\n",
    "测试环境\n",
    "\n",
    "进入jetson_inference文件夹的yolov3例程\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e4bc5849847e4697b8a028555aa24d583899f9b7ad094e8b9181d29e088a974f)\n",
    "\n",
    "运行bash run.sh将例程跑通就可以开始，或者可以跑resnet50的例程\n",
    "\n",
    "注意，如果报缺少包的错误则需要将run.sh文件中执行的python 改为python3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "单张图像预测demo：\n",
    "\n",
    "在yolov3目录下创建 predict.py，复制以下代码\n",
    "\n",
    "下面将给出视频流和加上位机的demo，因为是根据例程改的，改的有些乱所以直接都给出\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from paddle.inference import Config\n",
    "from paddle.inference import create_predictor\n",
    "\n",
    "from utils import preprocess, draw_bbox\n",
    "\n",
    "\n",
    "def init_predictor(args):\n",
    "    if args.model_dir != \"\":\n",
    "        config = Config(args.model_dir)\n",
    "    else:\n",
    "        config = Config(args.model_file, args.params_file)\n",
    "\n",
    "    config.enable_memory_optim()\n",
    "    if args.use_gpu:\n",
    "        config.enable_use_gpu(500, 0)\n",
    "    else:\n",
    "        # If not specific mkldnn, you can set the blas thread.\n",
    "        # The thread num should not be greater than the number of cores in the CPU.\n",
    "        config.set_cpu_math_library_num_threads(4)\n",
    "        config.enable_mkldnn()\n",
    "\n",
    "    predictor = create_predictor(config)\n",
    "    return predictor\n",
    "\n",
    "\n",
    "def run(predictor, img):\n",
    "    # copy img data to input tensor\n",
    "    input_names = predictor.get_input_names()\n",
    "    for i, name in enumerate(input_names):\n",
    "        input_tensor = predictor.get_input_handle(name)\n",
    "        input_tensor.reshape(img[i].shape)\n",
    "        input_tensor.copy_from_cpu(img[i].copy())\n",
    "\n",
    "    # do the inference\n",
    "    predictor.run()\n",
    "\n",
    "    results = []\n",
    "    # get out data from output tensor\n",
    "    output_names = predictor.get_output_names()\n",
    "    for i, name in enumerate(output_names):\n",
    "        output_tensor = predictor.get_output_handle(name)\n",
    "        output_data = output_tensor.copy_to_cpu()\n",
    "        results.append(output_data)\n",
    "    return results\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--model_file\",\n",
    "        type=str,\n",
    "        default=\"yolov3_darknet53_270e_voc/model.pdmodel\",\n",
    "        help=\"Model filename, Specify this when your model is a combined model.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--params_file\",\n",
    "        type=str,\n",
    "        default=\"yolov3_darknet53_270e_voc/model.pdiparams\",\n",
    "        help=\n",
    "        \"Parameter filename, Specify this when your model is a combined model.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_dir\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "        help=\n",
    "        \"Model dir, If you load a non-combined model, specify the directory of the model.\"\n",
    "    )\n",
    "    parser.add_argument(\"--use_gpu\",\n",
    "                        type=int,\n",
    "                        default=0,\n",
    "                        help=\"Whether use gpu.\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    img_name = 'one1.jpg'\n",
    "    save_img_name = 'res.jpg'\n",
    "    im_size = 608\n",
    "    pred = init_predictor(args)\n",
    "    img = cv2.imread(img_name)\n",
    "    data = preprocess(img, im_size)\n",
    "    scale_factor = np.array([im_size * 1. / img.shape[0], im_size * 1. / img.shape[1]]).reshape((1, 2)).astype(np.float32)\n",
    "    im_shape = np.array([im_size, im_size]).reshape((1, 2)).astype(np.float32)\n",
    "    result = run(pred, [im_shape, data, scale_factor])\n",
    "    img = Image.open(img_name).convert('RGB')\n",
    "    draw_bbox(img, result[0], save_name=save_img_name)\n",
    "```\n",
    "\n",
    "如果训练的模型也是yolov3_darknet53_270e_voc，则直接在相同目录下执行\n",
    "\n",
    "`python3 predict.py`\n",
    "\n",
    "如果不是则在命令行中加入相应的文件地址\n",
    "\n",
    "示例\n",
    "\n",
    "`python3 predict.py --model_file 相对路径.pdmodel --params_file 相对路径.pdiparams --use_gpu 0`\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f3d2f7426bf443a2bccea208f8bee51407d96ef5b2ae46898d478e52d294f825)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/7a80784efc0e4f20b1b5f248482b63d96bae1aadecb04db69665258c937ee7c6)\n",
    "\n",
    "运行成功应为上图结果\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "视频流检测demo：\n",
    "```\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "from paddle.inference import Config\n",
    "from paddle.inference import create_predictor\n",
    "from paddle.inference import PrecisionType\n",
    "\n",
    "from utils import preprocess, draw_bbox,return_bbox\n",
    "\n",
    "\n",
    "def init_predictor(args):\n",
    "    if args.model_dir != \"\":\n",
    "        config = Config(args.model_dir)\n",
    "    else:\n",
    "        config = Config(args.model_file, args.params_file)\n",
    "\n",
    "    config.enable_memory_optim()\n",
    "    if args.use_gpu:\n",
    "        config.switch_ir_optim()\n",
    "        config.enable_use_gpu(500, 0)\n",
    "    else:\n",
    "        # If not specific mkldnn, you can set the blas thread.\n",
    "        # The thread num should not be greater than the number of cores in the CPU.\n",
    "        config.set_cpu_math_library_num_threads(4)\n",
    "        config.enable_mkldnn()\n",
    "    config.enable_tensorrt_engine(workspace_size=1 << 30, precision_mode=PrecisionType.Half,max_batch_size=1, min_subgraph_size=5, use_static=False, use_calib_mode=False)\n",
    "    predictor = create_predictor(config)\n",
    "    return predictor\n",
    "\n",
    "\n",
    "def run(predictor, img):\n",
    "    # copy img data to input tensor\n",
    "    input_names = predictor.get_input_names()\n",
    "    for i, name in enumerate(input_names):\n",
    "        input_tensor = predictor.get_input_handle(name)\n",
    "        input_tensor.reshape(img[i].shape)\n",
    "        input_tensor.copy_from_cpu(img[i].copy())\n",
    "\n",
    "    # do the inference\n",
    "    predictor.run()\n",
    "\n",
    "    results = []\n",
    "    # get out data from output tensor\n",
    "    output_names = predictor.get_output_names()\n",
    "    for i, name in enumerate(output_names):\n",
    "        output_tensor = predictor.get_output_handle(name)\n",
    "        output_data = output_tensor.copy_to_cpu()\n",
    "        results.append(output_data)\n",
    "    return results\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--model_file\",\n",
    "        type=str,\n",
    "        default=\"yolov3_mobilenet_v1_ssld_270e_voc/model.pdmodel\",\n",
    "        help=\"Model filename, Specify this when your model is a combined model.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--params_file\",\n",
    "        type=str,\n",
    "        default=\"yolov3_mobilenet_v1_ssld_270e_voc/model.pdiparams\",\n",
    "        help=\n",
    "        \"Parameter filename, Specify this when your model is a combined model.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_dir\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "        help=\n",
    "        \"Model dir, If you load a non-combined model, specify the directory of the model.\"\n",
    "    )\n",
    "    parser.add_argument(\"--use_gpu\",\n",
    "                        type=int,\n",
    "                        default=1,\n",
    "                        help=\"Whether use gpu.\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "\n",
    "\n",
    "    im_size =320\n",
    "    pred = init_predictor(args)\n",
    "\n",
    "    capture = cv2.VideoCapture(0)\n",
    "    fps = 0.0\n",
    "    while(True):\n",
    "        t1 = time.time()\n",
    "        ref, img = capture.read()\n",
    "        if not ref:\n",
    "            break\n",
    "        img= cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        data = preprocess(img, im_size)\n",
    "        scale_factor = np.array([im_size * 1. / img.shape[0], im_size * 1. / img.shape[1]]).reshape((1, 2)).astype(np.float32)\n",
    "        im_shape = np.array([im_size, im_size]).reshape((1, 2)).astype(np.float32)\n",
    "        result = run(pred, [im_shape, data, scale_factor])\n",
    "        fps  = ( fps + (1./(time.time()-t1)) ) / 2\n",
    "        print(\"fps= %.2f\"%(fps))\n",
    "        return_bbox(result[0]) \n",
    "        #print(len(result[0]))\n",
    "        c = cv2.waitKey(1) & 0xff \n",
    "        if c==27:\n",
    "            capture.release()\n",
    "            break\n",
    "\t\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "上位机加视频流检测demo：\n",
    "```\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "from paddle.inference import Config\n",
    "from paddle.inference import create_predictor\n",
    "from paddle.inference import PrecisionType\n",
    "\n",
    "from utils import preprocess, draw_bbox\n",
    "import serial as ser\n",
    "import struct,time\n",
    "\n",
    "se = ser.Serial(    \n",
    "    port=\"/dev/ttyACM0\",\n",
    "    baudrate=115200,\n",
    "    bytesize=ser.EIGHTBITS,\n",
    "    parity=ser.PARITY_NONE,\n",
    "    stopbits=ser.STOPBITS_ONE\n",
    "    \n",
    ")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "flag = 0\n",
    "\n",
    "def init_predictor(args):\n",
    "    if args.model_dir != \"\":\n",
    "        config = Config(args.model_dir)\n",
    "    else:\n",
    "        config = Config(args.model_file, args.params_file)\n",
    "\n",
    "    config.enable_memory_optim()\n",
    "    if args.use_gpu:\n",
    "        config.switch_ir_optim()\n",
    "        config.enable_use_gpu(500, 0)\n",
    "    else:\n",
    "        # If not specific mkldnn, you can set the blas thread.\n",
    "        # The thread num should not be greater than the number of cores in the CPU.\n",
    "        config.set_cpu_math_library_num_threads(4)\n",
    "        config.enable_mkldnn()\n",
    "    #config.enable_tensorrt_engine(workspace_size=1 << 30, precision_mode=PrecisionType.Half,max_batch_size=1, min_subgraph_size=5, use_static=False, use_calib_mode=False)\n",
    "    predictor = create_predictor(config)\n",
    "    return predictor\n",
    "\n",
    "def run(predictor, img):\n",
    "    # copy img data to input tensor\n",
    "    input_names = predictor.get_input_names()\n",
    "    for i, name in enumerate(input_names):\n",
    "        input_tensor = predictor.get_input_handle(name)\n",
    "        input_tensor.reshape(img[i].shape)\n",
    "        input_tensor.copy_from_cpu(img[i].copy())\n",
    "\n",
    "    # do the inference\n",
    "    predictor.run()\n",
    "\n",
    "    results = []\n",
    "    # get out data from output tensor\n",
    "    output_names = predictor.get_output_names()\n",
    "    for i, name in enumerate(output_names):\n",
    "        output_tensor = predictor.get_output_handle(name)\n",
    "        output_data = output_tensor.copy_to_cpu()\n",
    "        results.append(output_data)\n",
    "    return results\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--model_file\",\n",
    "        type=str,\n",
    "        default=\"ppyolo_mbv3_small_coco/model.pdmodel\",\n",
    "        help=\"Model filename, Specify this when your model is a combined model.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--params_file\",\n",
    "        type=str,\n",
    "        default=\"ppyolo_mbv3_small_coco/model.pdiparams\",\n",
    "        help=\n",
    "        \"Parameter filename, Specify this when your model is a combined model.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_dir\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "        help=\n",
    "        \"Model dir, If you load a non-combined model, specify the directory of the model.\"\n",
    "    )\n",
    "    parser.add_argument(\"--use_gpu\",\n",
    "                        type=int,\n",
    "                        default=0,\n",
    "                        help=\"Whether use gpu.\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "def return_bbox(result, threshold=0.5):\n",
    "    \"\"\"draw bbox\"\"\"\n",
    "    all_bbox = []\n",
    "    for res in result:\n",
    "        cat_id, score, bbox = res[0], res[1], res[2:]\n",
    "        if score < threshold:\n",
    "            continue\n",
    "            return all_bbox\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        all_bbox.append({\"id\":cat_id,\"score\":score,\"location\":bbox  })\n",
    "        print('category id is {}, bbox is {}'.format(cat_id, bbox))\n",
    "        return all_bbox\n",
    "        #if len(all_bbox):\n",
    "        #        print(int(all_bbox[-1]['id']))\n",
    "        #        if flag!=int(all_bbox[-1]['id']):            \n",
    "        #                se.write((str(int(all_bbox[-1]['id'])+1)+\"\\n\").encode())\n",
    "        #        flag = int(all_bbox[-1]['id'])\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    im_size =320\n",
    "    pred = init_predictor(args)\n",
    "    all_bbox = []\t\n",
    "    capture = cv2.VideoCapture(0)\n",
    "    fps = 0.0\n",
    "    while(True):\n",
    "        t1 = time.time()\n",
    "        ref, img = capture.read()\n",
    "        if not ref:\n",
    "            break\n",
    "        img= cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        data = preprocess(img, im_size)\n",
    "        scale_factor = np.array([im_size * 1. / img.shape[0], im_size * 1. / img.shape[1]]).reshape((1, 2)).astype(np.float32)\n",
    "        im_shape = np.array([im_size, im_size]).reshape((1, 2)).astype(np.float32)\n",
    "        result = run(pred, [im_shape, data, scale_factor])\n",
    "        fps  = ( fps + (1./(time.time()-t1)) ) / 2\n",
    "        print(\"fps= %.2f\"%(fps))\n",
    "        all_box = return_bbox(result[0]) \n",
    "        if len(all_bbox)>0:\n",
    "                print(int(all_bbox[-1]['id']))\n",
    "                if flag!=int(all_bbox[-1]['id']):            \n",
    "                        se.write((str(int(all_bbox[-1]['id'])+1)+\"\\n\").encode())\n",
    "                flag = int(all_bbox[-1]['id'])\n",
    "\n",
    "        \n",
    "        #print(len(result[0]))\n",
    "        c = cv2.waitKey(1) & 0xff \n",
    "        if c==27:\n",
    "            capture.release()\n",
    "            break\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "最后的文件夹结构是\n",
    "\n",
    "||\n",
    "\n",
    "||---weight\n",
    "\n",
    "||\n",
    "\n",
    "||---util.py\n",
    "\n",
    "||\n",
    "\n",
    "||---video.py\n",
    "\n",
    "||\n",
    "\n",
    "其中weight是经paddledetection导出后的权重模型\n",
    "video.py是你使用的视频流检测demo还是单张图检测demo还是带上位机的部分\n",
    "\n",
    "\n",
    "util.py代码\n",
    "```\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "def resize(img, target_size):\n",
    "    \"\"\"resize to target size\"\"\"\n",
    "    if not isinstance(img, np.ndarray):\n",
    "        raise TypeError('image type is not numpy.')\n",
    "    im_shape = img.shape\n",
    "    im_size_min = np.min(im_shape[0:2])\n",
    "    im_size_max = np.max(im_shape[0:2])\n",
    "    im_scale_x = float(target_size) / float(im_shape[1])\n",
    "    im_scale_y = float(target_size) / float(im_shape[0])\n",
    "    img = cv2.resize(img, None, None, fx=im_scale_x, fy=im_scale_y)\n",
    "    return img\n",
    "\n",
    "\n",
    "def normalize(img, mean, std):\n",
    "    img = img / 255.0\n",
    "    mean = np.array(mean)[np.newaxis, np.newaxis, :]\n",
    "    std = np.array(std)[np.newaxis, np.newaxis, :]\n",
    "    img -= mean\n",
    "    img /= std\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess(img, img_size):\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    img = resize(img, img_size)\n",
    "    img = img[:, :, ::-1].astype('float32')  # bgr -> rgb\n",
    "    img = normalize(img, mean, std)\n",
    "    img = img.transpose((2, 0, 1))  # hwc -> chw\n",
    "    return img[np.newaxis, :]\n",
    "\n",
    "\n",
    "def draw_bbox(img, result, threshold=0.5, save_name='res.jpg'):\n",
    "    \"\"\"draw bbox\"\"\"\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for res in result:\n",
    "        cat_id, score, bbox = res[0], res[1], res[2:]\n",
    "        if score < threshold:\n",
    "            continue\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        draw.line([(xmin, ymin), (xmin, ymax), (xmax, ymax), (xmax, ymin),\n",
    "                   (xmin, ymin)],\n",
    "                  width=2,\n",
    "                  fill=(255, 0, 0))\n",
    "        print('category id is {}, bbox is {}'.format(cat_id, bbox))\n",
    "    img.save(save_name, quality=95)\n",
    "\n",
    "def return_bbox(result, threshold=0.5):\n",
    "    \"\"\"draw bbox\"\"\"\n",
    "    all_bbox = []\n",
    "    for res in result:\n",
    "        cat_id, score, bbox = res[0], res[1], res[2:]\n",
    "        if score < threshold:\n",
    "            continue\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        all_bbox.append({\"id\":cat_id,\"score\":score,\"location\":bbox  })\n",
    "        print('category id is {}, bbox is {}'.format(cat_id, bbox))\n",
    "    return all_bbox\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 7.Arduino部分代码\n",
    "\n",
    "Arduino使用到了PWM库\n",
    "\n",
    "PWM库给出网盘链接\n",
    "\n",
    "[链接：https://pan.baidu.com/s/1pEHHU1nfRWSwO00rkM0WOg \n",
    "提取码：haha](http://)\n",
    "\n",
    "```\n",
    "#include <PWM.h>\n",
    "\n",
    "#define dDo 175 \n",
    "#define dRe 196  \n",
    "#define dMi 221  \n",
    "#define dFa 234  \n",
    "#define dSol 262  \n",
    "#define dLa 294\n",
    "#define dSi 330\n",
    "\n",
    "#define Do 350\n",
    "#define Re 393  \n",
    "#define Mi 441 \n",
    "#define Fa 495  \n",
    "#define Sol 556\n",
    "#define La 624\n",
    "#define Si 661 \n",
    "\n",
    "int pin = 9;                // led所连接到的引脚\n",
    "int brightness = 100;         // led的亮度，也就是占空比，范围是0-255\n",
    "//0-6,7-14,14-20\n",
    "int32_t fre[21]={dDo,dRe,dMi,dFa,dSol,dLa,dSi,Do,Re,Mi,Fa,Sol,La,Si};\n",
    "\n",
    "int message = 0;//用于接收信息进行对比\n",
    "\n",
    "//void cf(int32_t mark,int32_t last,int32_t h_l=1)\n",
    "void cf(int32_t mark)//mark 为标号，last 为持续时长\n",
    "{\n",
    "    mark-=1;  \n",
    "    bool success = SetPinFrequencySafe(pin, fre[mark]);\n",
    "    pwmWrite(pin, brightness);\n",
    "}\n",
    "\n",
    "void setup()\n",
    "{\n",
    "  // 初始化除了0号计时器以外的其他计时器\n",
    "  InitTimersSafe(); \n",
    "\n",
    "  // 设置指定引脚的频率\n",
    "  bool success = SetPinFrequencySafe(pin, dDo);\n",
    "\n",
    "  delay(300);\n",
    "  Serial.begin(9600);//初始化串口函数\n",
    "  \n",
    "\n",
    "}\n",
    "\n",
    "void loop()\n",
    "{\n",
    "  //Serial.println(\"6\");\n",
    "//  Serial.println(Serial.parseInt());\n",
    "\n",
    "  if (Serial.available() > 0)//串口接收到数据\n",
    "  {\n",
    "      int incomedate = Serial.parseInt();//获取串口接收到的数据\n",
    "      Serial.println(incomedate);\n",
    "//      pwmWrite(pin, brightness);\n",
    "//      delay(300);\n",
    "      if (incomedate>0){\n",
    "        cf(incomedate);\n",
    "\n",
    "        delay(300);\n",
    "        Serial.println(incomedate);\n",
    "        pwmWrite(pin, 0);\n",
    "\n",
    "      }\n",
    "\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "B站视频链接https://www.bilibili.com/video/BV1134y1q7FY?spm_id_from=333.999.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
